{
  "metadata": {
    "title": "Randomized Experiments and Monte Carlo Simulations",
    "date": "2021-01-30",
    "author": "Youngmin Ju",
    "excerpt": "Explore the implementation of randomized experiments and Monte Carlo simulations for causal inference and statistical analysis.",
    "thumbnail": "/images/ds3.png",
    "tags": ["Randomized Experiments", "Monte Carlo", "Simulation", "Statistics"]
  },
  "content": "# Randomized Experiments & Monte Carlo Simulation\n\nRandomized experiments are the gold standard for causal inference. Monte Carlo simulations help us understand the properties of statistical methods under various conditions.\n\n## Data Generating Process (DGP)\n\nWe can simulate data with known causal effects to evaluate estimation methods:\n\n```python\nimport numpy as np\nimport random\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\ndef fn_generate_data(tau, N, p, p0, corr, conf=True, flagX=False):\n    \"\"\"\n    Generate synthetic data for experiments\n    \n    Parameters:\n    tau (float): True treatment effect\n    N (int): Sample size\n    p (int): Number of covariates\n    p0 (int): Number of covariates with nonzero coefficients\n    corr (float): Correlation for multivariate normal\n    conf (bool): Whether to include confounders\n    flagX (bool): Whether to return covariates\n    \"\"\"\n    nvar = p+2 # 1 confounder and variable for randomizing treatment\n    corr = 0.5 # correlation for multivariate normal\n\n    if conf==False:\n        conf_mult = 0 # remove confounder from outcome\n        \n    allX = fn_generate_multnorm(N, corr, nvar)\n    C = allX[:,1].reshape([N,1]) # confounder\n    X = allX[:,2:] # observed covariates\n    \n    T = fn_randomize_treatment(N) # choose treated units\n    err = np.random.normal(0,1,[N,1])\n    beta0 = np.random.normal(5,5,[p,1])\n    \n    beta0[p0:p] = 0 # sparse model\n    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n    if flagX==False:\n        return (Yab,T)\n    else:\n        return (Yab,T,X)\n```\n\n## Experiments with No Covariates\n\nThe simplest case is when the outcome depends only on treatment:\n\ny_i = τ*T_i + e_i\n\n```python\ntau = 2\ncorr = .5\nconf = False\np = 10\np0 = 0 # number of covariates used in the DGP\nNrange = range(10,1000,2) # loop over N values\n(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)\n```\n\n## Experiments with Covariates\n\nA more realistic scenario includes covariates:\n\ny_i = τ*T_i + β'*x_i + e_i\n\n```python\ntau = 2\ncorr = .5\nconf = False\np = 100\np0 = 50 # number of covariates used in the DGP\nNrange = range(100,1000,2) # loop over N values\nflagX = 1\n(nvalues2,tauhats2,sehats2,lb2,ub2) = fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX)\n```\n\n## Cross-Validation\n\nK-fold cross-validation helps us evaluate model performance:\n\n```python\nfrom sklearn.model_selection import KFold\n\ncv = KFold(n_splits=5)\nfor train_idx, test_idx in cv.split(X):\n    # Train on train_idx\n    # Test on test_idx\n    lrm = LogisticRegression(C=1.0, solver='lbfgs', max_iter=10000)\n    lrm.fit(X_train.iloc[train_idx,:], y_train.iloc[train_idx])\n    lrm_pred = lrm.predict(X_train.iloc[test_idx,:])\n    y_val = y_train.iloc[test_idx]\n    \n    print('Accuracy:', metrics.accuracy_score(y_val, lrm_pred))\n```\n\n## Key Findings\n\n1. Randomization ensures unbiased estimation of treatment effects\n2. Including relevant covariates improves precision\n3. Including irrelevant covariates can reduce precision\n4. Cross-validation helps select the best model specification"
}
